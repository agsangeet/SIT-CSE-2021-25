{"cells":[{"cell_type":"markdown","metadata":{"id":"_ZDPR5UcfOn_"},"source":["# Assignment 1: Exp 1\n"]},{"cell_type":"markdown","source":["Exp 1 - a)"],"metadata":{"id":"8476vkSJRNTa"}},{"cell_type":"code","source":["# AND Function\n","\n","def mcCulloch_pitts_and_t1(inputs):\n","    # Adjusted weights for AND function\n","    weights = [0.5, 0.5]\n","    threshold = 1\n","\n","    # calculate the weighted sum\n","    weighted_sum = sum(weight * input_val for weight, input_val in zip(weights, inputs))\n","\n","    # apply the threshold to get the output\n","    output = 1 if weighted_sum >= threshold else 0\n","\n","    return output\n","\n","def mcCulloch_pitts_and_t2(inputs):\n","    # weights for AND function\n","    weights = [1, 1]\n","    threshold = 2\n","\n","    # calculate the weighted sum\n","    weighted_sum = sum(weight * input_val for weight, input_val in zip(weights, inputs))\n","\n","    # apply the threshold to get the output\n","    output = 1 if weighted_sum >= threshold else 0\n","\n","    return output\n","\n","# Test inputs\n","test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n","\n","print(\"\\nAND Function with T = 1\")\n","for inputs in test_inputs:\n","    print(f\"Inputs: {inputs} -> Output: {mcCulloch_pitts_and_t1(inputs)}\")\n","\n","print(\"AND Function with T = 2\")\n","for inputs in test_inputs:\n","    print(f\"Inputs: {inputs} -> Output: {mcCulloch_pitts_and_t2(inputs)}\")"],"metadata":{"id":"H6xuSwHyQ94N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Exp 1 - b)"],"metadata":{"id":"kkOxrdN4RVR1"}},{"cell_type":"code","source":["# OR Function\n","\n","def mcCulloch_pitts_or(inputs, threshold):\n","    # weights for OR function\n","    weights = [1, 1]\n","\n","    # calculate the weighted sum\n","    weighted_sum = sum(weight * input_val for weight, input_val in zip(weights, inputs))\n","\n","    # apply the threshold to get the output\n","    output = 1 if weighted_sum >= threshold else 0\n","\n","    return output\n","\n","# Test with threshold T = 1\n","threshold_1 = 1\n","test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n","\n","print(\"OR Function with T = 1\")\n","for inputs in test_inputs:\n","    print(f\"Inputs: {inputs} -> Output: {mcCulloch_pitts_or(inputs, threshold_1)}\")"],"metadata":{"id":"1exyAU7pRW2l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x_yc4psliH3I"},"source":["# Assignment 1: Exp 2\n"]},{"cell_type":"markdown","source":["Exp 2 - c"],"metadata":{"id":"1i_9Rs0nRnAu"}},{"cell_type":"code","source":["# XOR Function\n","\n","def mcculloch_pitts_neuron(inputs, weights, threshold):\n","    weighted_sum = sum(w * i for w, i in zip(weights, inputs))\n","    return 1 if weighted_sum >= threshold else 0\n","\n","def xor_mcculloch_pitts(x1, x2):\n","    # Neuron 1 (OR gate)\n","    n1_output = mcculloch_pitts_neuron([x1, x2], [1, 1], 1)\n","\n","    # Neuron 2 (AND gate)\n","    n2_output = mcculloch_pitts_neuron([x1, x2], [1, 1], 2)\n","\n","    # Neuron 3 (XOR gate)\n","    xor_output = mcculloch_pitts_neuron([n1_output, n2_output], [1, -2], 1)\n","\n","    return xor_output\n","\n","# Test the XOR function\n","print(\"XOR Function Outputs:\")\n","for x1 in [0, 1]:\n","    for x2 in [0, 1]:\n","        print(f\"XOR({x1}, {x2}) = {xor_mcculloch_pitts(x1, x2)}\")"],"metadata":{"id":"y9W8YAXsRmsK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Exp 2 - d"],"metadata":{"id":"-ofssJlgRpTD"}},{"cell_type":"code","source":["# NAND Function\n","\n","\n","def mcCulloch_pitts_nand(inputs):\n","    # Weights for NAND function\n","    weights = [-1, -1]\n","    threshold = -0.5\n","\n","    # Calculate the weighted sum\n","    weighted_sum = sum(weight * input_val for weight, input_val in zip(weights, inputs))\n","\n","    # Apply the threshold to get the output\n","    output = 1 if weighted_sum >= threshold else 0\n","\n","    return output\n","\n","# Test inputs\n","test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n","\n","print(\"\\nNAND Function:\")\n","for inputs in test_inputs:\n","    print(f\"Inputs: {inputs} -> Output: {mcCulloch_pitts_nand(inputs)}\")"],"metadata":{"id":"SSuHHZ_DRpA0"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"Ykiw9sDtyyFZ","outputId":"e90da01f-edc1-4891-8fbd-fcd0d15c296e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Episode 0: Q-table size 4\n","Episode 50: Q-table size 256\n","Episode 100: Q-table size 506\n","Episode 150: Q-table size 734\n","Episode 200: Q-table size 1018\n","Episode 250: Q-table size 1248\n","Episode 300: Q-table size 1467\n","Episode 350: Q-table size 1731\n","Episode 400: Q-table size 1967\n","Episode 450: Q-table size 2190\n"]}],"source":["import numpy as np\n","import random\n","import pygame\n","\n","# Constants\n","GRID_SIZE = 10\n","ACTIONS = [(0, 1), (0, -1), (1, 0), (-1, 0), (1, 1), (-1, -1), (-1, 1), (1, -1)]  # 8 degrees of movement\n","ALPHA = 0.1  # Learning rate\n","GAMMA = 0.9  # Discount factor\n","EPSILON = 0.1  # Exploration factor\n","CELL_SIZE = 50  # Size of each cell in the grid\n","\n","# Initialize pygame\n","pygame.init()\n","screen = pygame.display.set_mode((GRID_SIZE * CELL_SIZE, GRID_SIZE * CELL_SIZE))\n","pygame.display.set_caption(\"Cat and Mouse Game\")\n","clock = pygame.time.Clock()\n","\n","# Define colors\n","WHITE = (255, 255, 255)\n","BLACK = (0, 0, 0)\n","RED = (255, 0, 0)\n","BLUE = (0, 0, 255)\n","YELLOW = (255, 255, 0)\n","\n","# Define the environment (Cat and Mouse Grid)\n","class CatMouseEnv:\n","    def __init__(self, grid_size):\n","        self.grid_size = grid_size\n","        self.reset()\n","\n","    def reset(self):\n","        # Place mouse, cat, and cheese in random positions\n","        self.mouse_pos = [random.randint(0, self.grid_size - 1), random.randint(0, self.grid_size - 1)]\n","        self.cat_pos = [random.randint(0, self.grid_size - 1), random.randint(0, self.grid_size - 1)]\n","        self.cheese_pos = [random.randint(0, self.grid_size - 1), random.randint(0, self.grid_size - 1)]\n","        return self.get_state()\n","\n","    def get_state(self):\n","        return tuple(self.mouse_pos + self.cat_pos + self.cheese_pos)\n","\n","    def is_valid(self, pos):\n","        return 0 <= pos[0] < self.grid_size and 0 <= pos[1] < self.grid_size\n","\n","    def step(self, action):\n","        # Move mouse\n","        new_mouse_pos = [self.mouse_pos[0] + action[0], self.mouse_pos[1] + action[1]]\n","        if self.is_valid(new_mouse_pos):\n","            self.mouse_pos = new_mouse_pos\n","\n","        # Move cat towards mouse\n","        self.move_cat()\n","\n","        # Check for win/lose condition\n","        if self.mouse_pos == self.cheese_pos:\n","            reward = 1  # Mouse gets cheese\n","            done = False  # Game continues after getting the cheese\n","            self.cheese_pos = [random.randint(0, self.grid_size - 1), random.randint(0, self.grid_size - 1)]  # New cheese position\n","        elif self.mouse_pos == self.cat_pos:\n","            reward = -1  # Cat catches mouse\n","            done = True  # Game ends when the cat catches the mouse\n","        else:\n","            reward = 0  # No one has won yet\n","            done = False\n","\n","        return self.get_state(), reward, done\n","\n","    def move_cat(self):\n","        if self.cat_pos[0] < self.mouse_pos[0]:\n","            self.cat_pos[0] += 1\n","        elif self.cat_pos[0] > self.mouse_pos[0]:\n","            self.cat_pos[0] -= 1\n","\n","        if self.cat_pos[1] < self.mouse_pos[1]:\n","            self.cat_pos[1] += 1\n","        elif self.cat_pos[1] > self.mouse_pos[1]:\n","            self.cat_pos[1] -= 1\n","\n","    def render(self):\n","        # Draw grid\n","        screen.fill(WHITE)\n","        for row in range(self.grid_size):\n","            for col in range(self.grid_size):\n","                pygame.draw.rect(screen, BLACK, pygame.Rect(col * CELL_SIZE, row * CELL_SIZE, CELL_SIZE, CELL_SIZE), 1)\n","\n","        # Draw mouse, cat, and cheese\n","        pygame.draw.rect(screen, BLUE, pygame.Rect(self.mouse_pos[1] * CELL_SIZE, self.mouse_pos[0] * CELL_SIZE, CELL_SIZE, CELL_SIZE))\n","        pygame.draw.rect(screen, RED, pygame.Rect(self.cat_pos[1] * CELL_SIZE, self.cat_pos[0] * CELL_SIZE, CELL_SIZE, CELL_SIZE))\n","        pygame.draw.rect(screen, YELLOW, pygame.Rect(self.cheese_pos[1] * CELL_SIZE, self.cheese_pos[0] * CELL_SIZE, CELL_SIZE, CELL_SIZE))\n","        pygame.display.flip()\n","\n","# Q-learning Agent\n","class QLearningAgent:\n","    def __init__(self, actions, alpha=ALPHA, gamma=GAMMA, epsilon=EPSILON):\n","        self.q_table = {}  # Q-table: maps state-action pairs to rewards\n","        self.actions = actions\n","        self.alpha = alpha\n","        self.gamma = gamma\n","        self.epsilon = epsilon\n","\n","    def get_q_value(self, state, action):\n","        return self.q_table.get((state, action), 0.0)\n","\n","    def update_q_value(self, state, action, reward, next_state):\n","        old_q_value = self.get_q_value(state, action)\n","        max_next_q_value = max([self.get_q_value(next_state, a) for a in self.actions])\n","        new_q_value = old_q_value + self.alpha * (reward + self.gamma * max_next_q_value - old_q_value)\n","        self.q_table[(state, action)] = new_q_value\n","\n","    def choose_action(self, state):\n","        if random.uniform(0, 1) < self.epsilon:  # Explore\n","            return random.choice(self.actions)\n","        else:  # Exploit\n","            q_values = [self.get_q_value(state, action) for action in self.actions]\n","            max_q = max(q_values)\n","            return self.actions[q_values.index(max_q)]\n","\n","# Main loop to run the simulation with pygame visualization\n","def run_simulation(episodes=500):\n","    env = CatMouseEnv(GRID_SIZE)\n","    agent = QLearningAgent(ACTIONS)\n","\n","    for episode in range(episodes):\n","        state = env.reset()\n","        done = False\n","        while not done:\n","            # Handle Pygame events (for closing the window)\n","            for event in pygame.event.get():\n","                if event.type == pygame.QUIT:\n","                    pygame.quit()\n","                    return\n","\n","            # Choose action and take a step in the environment\n","            action = agent.choose_action(state)\n","            next_state, reward, done = env.step(action)\n","            agent.update_q_value(state, action, reward, next_state)\n","            state = next_state\n","\n","            # Render the environment\n","            env.render()\n","\n","            # Control the frame rate\n","            clock.tick(5)\n","\n","            if done:\n","                break  # Terminate the game if the cat catches the mouse\n","\n","        if episode % 50 == 0:\n","            print(f\"Episode {episode}: Q-table size {len(agent.q_table)}\")\n","\n","\n","if __name__ == \"__main__\":\n","    run_simulation()"]}],"metadata":{"colab":{"toc_visible":true,"provenance":[],"collapsed_sections":["_ZDPR5UcfOn_","x_yc4psliH3I"],"authorship_tag":"ABX9TyOUmZQIjHhpD/OP47jr6a76"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}